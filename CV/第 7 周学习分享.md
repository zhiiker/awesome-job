时间：2019年5月6日 ~ 2019年5月12日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
唐洋 | 学习基于深度学习的目标检测框架 | 总结R-CNN、SPP-NET、Fast R-CNN、Faster R-CNN、YOLO(v1 v2)、SSD [参考](https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html#fast-r-cnn)
安军刚 | 对偶学习 | 目前在图像方向随着大量的顶会论文出现确实推动了工业界发展，做为学术界很多人从特征提取卷积修改、激活函数设计、损失函数优化几个方向重构着行业的未来，但是仔细阅读这些论文的本质用分析数学的思考考虑借助迈克尔-乔丹教授提出的修改采样方式比优化模型更能解决模型存在的本身问题思考，任何一个问题我们从不同的粒度去理解它之后问题的解是相通的这个就是对偶学习最通俗的概念。对偶学习的新思路是为了解决庞大的数据运算而比较温和的方向，计算机的底层逻辑门是01执行的汇编机器码这种在流水线上没法实现乘法和除法高级运算，借助语言层次实现的乘除法作为微积分计算的基础它的执行在一定程度上给计算带来负担同时让计算变得非常复杂。例如在FPGA上直接实现VGG是非常工作量大的一个工作，文字和图像是人类对自然客观表示的一种方式，那么针对一个模型你可以把它进行数学语言描述后就是一个方程在不同的学术背景下可以不同的角度进行求解，这种不唯一性有可能从根本上解决代码层面的和谐问题。  目前出现的论文和开源代码在实现上有出入的现象。
> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 唐洋的学习心得
### 提前的总结
#### 方案1.候选区域 + 深度学习回归（two stage）
[R-CNN](http://arxiv.org/abs/1311.2524)，2014（Selective Search + CNN + SVM），首先预选2000个框

[SPP-Net](http://arxiv.org/abs/1406.4729)，2015（ROI Pooling），一次卷积，不限制输入尺寸

[Fast R-CNN](http://arxiv.org/abs/1504.08083)，2015（Selective Search + CNN + ROI），结合R-CNN和SPP-Net的思路。将分类和回归都加入到网络中进行训练，做成了端到端。

[Faster R-CNN](http://arxiv.org/abs/1506.01497)，2015（RPN + CNN + ROI），用RPN来求候选框，同时引入anchor机制来应对目标形变问题。

#### 方案2. 深度学习回归（one stage）
[YOLO v1](http://arxiv.org/abs/1506.02640)，2016（回归任务）

[YOLO v2](https://arxiv.org/abs/1612.08242)，2017，引入Faster R-CNN的anchor机制

[SSD](http://arxiv.org/abs/1512.02325)，2016，结合YOLO的回归和Faster R-CNN的anchor

---

### 细节讨论

#### 1.R-CNN
1. 候选区域：利用颜色、纹理、边缘信息，使用selective search提取一定（2000）的框（在保持较高的recall情况下）。对于每个框的区域，需要修正区域大小，以适合于CNN的输入，并提取特征。
2. SVM分类：训练一个二分类SVM，来判断当前候选框里物体的类别。
3. 回归：使用回归来修正候选框的位置。
4. **问题1**：对2000个框都要进行CNN，框与框有重叠，时间复杂度高，在重叠区域的计算是不必要的，因此可以提速。
5. **问题2**：框的尺寸不一，需要resize，但是resize就会出现失真的问题。肯定会影响精度。

#### 2.SPP-Net
针对R-CNN的两个问题，SPP-Net就被提出来了。

1. ROI Pooling：在普通的CNN结构中加入了ROI Pooling，其中的pooling filter可根据输入调整大小，使得输出是一个固定维度的向量，输入可以是任意的尺寸。然后给到全连接FC层。
2. 对原图只做一次卷积，首先得到整张图的feature map，再找到每个候选框在feature map上所对应的区域，将这个区域的特征输入到ROI Pooling，完成特征提取的工作。

#### 3.Fast R-CNN
在R-CNN的基础上结合了SPP-Net的思路，相比原来R-CNN，使用一次卷积；在最后一次卷积后添加了ROI Pooling；将边框回归直接加入到了CNN网络中，因此做成了端到端网络。

R-CNN分为三个阶段，Fast R-CNN使用softmax来代替SVM，边框回归也加入到网络中，因此成为了端到端的网络。**这可以为后面改进阶段性的算法作为一个重要的提示**

R-CNN的方法：2000个候选框,resize -> CNN提取特征 -> 分类+回归

Fast R-CNN方法:原始图片 -> CNN -> ROI Pooling -> 分类+回归

相比R-CNN训练速度提升了8.8x， 测试速度提升了146x

**问题** Selective Search寻找候选框非常耗时，

#### 4.Faster R-CNN
引入RPN网络代替selective search，使用RPN来搜索候选框，同时引入anchor box应对目标形状的变化问题。

1. RPN：将RPN放在最后一个卷积层后面，所以RPN是作用在feature map上的，RPN包含分类和边框回归两个任务，分类器判断框属于的类别，边框回归进一步的优化/精细候选框。

---

#### 5.YOLO v1
*two stage*的方案不能满足实时性要求，所以one stage的出来了。

1. 首先将图像划分为7x7的网格
2. 对于每个网格，都预测2个边框（包括边框是目标的置信度和类别概率），最终可以得到7x7x2个边框，再经过NMS，即可得到最终的回归框。
3. **问题1**：只是用7x7的网格，使得回归的精度不够高。而且当每个格子中包含多个物体（>2）时，不能被检测出来。
4. **问题2**：输入图像输入resize到224*224

#### 6.YOLO v2
引入了Faster R-CNN的anchor box机制，并使用卷积层代替YOLO v1的全连接层，所以对输入图像不需要resize了。

1. 改进anchor box：Faster R-CNN中需要首选anchor box，而v2中采用k-means在许多框中进行聚类，以产生合适的框，同时使用过IOU作为k-means的距离计算。
2. 引入skip layer：借鉴ResNet的思想，使得网络更深。

#### 7.SSD
SSD结合了YOLO回归的思想和Faster R-CNN的anchor box机制，YOLO中预测某个位置使用的全图特征，SSD预测某个位置使用的这个位置周围的特征。

同时SSD的anchor是在多个feature map上进行的，这样就可以做的多尺度。
